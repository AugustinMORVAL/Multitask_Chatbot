models:
  - gemma2-9b-it
  - gemma-7b-it
  - llama3-70b-8192
  - llama3-8b-8192
  - mixtral-8x7b-32768

temperature_slider:
  min_value: 0.0
  max_value: 1.0
  value: 0.2
  step: 0.1
  help: "Controls the randomness of the model's responses."

system_prompt:
  value: "You are a helpful assistant."
  height: 100
  help: "Sets the context and behavior for the conversation."

cot_reflection:
  value: |
        You are an AI assistant that uses a Chain of Thought (CoT) approach with reflection to answer queries. Follow these steps:

        1. Think through the problem step by step within the <thinking> tags.
        2. Reflect on your thinking to check for any errors or improvements within the <reflection> tags.
        3. Make any necessary adjustments based on your reflection.
        4. Provide your final, concise answer within the <output> tags.

        Important: The <thinking> and <reflection> sections are for your internal reasoning process only. 
        Do not include any part of the final answer in these sections. 
        The actual response to the query must be entirely contained within the <output> tags.

        Use the following format for your response:
        <thinking>
        [Your step-by-step reasoning goes here. This is your internal thought process, not the final answer.]
        <reflection>
        [Your reflection on your reasoning, checking for errors or improvements]
        </reflection>
        [Any adjustments to your thinking based on your reflection]
        </thinking>
        <output>
        [Your final, concise answer to the query. This is the only part that will be shown to the user.]
        </output>
  height: 100
  help: "Sets a prompt for advanced problem-solving. The AI will show its reasoning process, self-reflect, and then provide a concise answer, improving accuracy and transparency."

max_tokens_slider:
  min_value: 100
  max_value: 4096
  value: 500
  step: 100
  help: "Controls the maximum number of tokens in the model's responses."

additional_parameters:
  top_p:
    label: "Top P"
    slider:
      min_value: 0.0
      max_value: 1.0
      value: 1.0
      step: 0.1
      help: "Set the probability threshold for generating a response."
  frequency_penalty:
    label: "Frequency Penalty"
    slider:
      min_value: 0.0
      max_value: 2.0
      value: 0.0
      step: 0.1
      help: "Penalize the model for repeating the same words or phrases."
  presence_penalty:
    label: "Presence Penalty"
    slider:
      min_value: 0.0
      max_value: 2.0
      value: 0.0
      step: 0.1
      help: "Penalize the model for using words or phrases already used in the conversation."
  stop:
    label: "Stop Sequences"
    input:
      value: ""
      help: "Specify sequences that the model should stop generating a response when encountered."

file_icons:
  pdf: üìÑ
  docx: üìù
  mp3: üéµ
  wav: üé∂
  ogg: üé∂