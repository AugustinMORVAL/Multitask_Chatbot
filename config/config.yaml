models:
  - gemma2-9b-it
  - gemma-7b-it
  - llama3-70b-8192
  - llama3-8b-8192
  - mixtral-8x7b-32768

temperature_slider:
  min_value: 0.0
  max_value: 1.0
  value: 0.2
  step: 0.1
  help: "Controls the randomness of the model's responses."

system_prompt:
  value: "You are a helpful assistant."
  height: 100
  help: "Sets the context and behavior for the conversation."

max_tokens_slider:
  min_value: 100
  max_value: 4096
  value: 500
  step: 100
  help: "Controls the maximum number of tokens in the model's responses."

additional_parameters:
  top_p:
    label: "Top P"
    slider:
      min_value: 0.0
      max_value: 1.0
      value: 1.0
      step: 0.1
      help: "Set the probability threshold for generating a response."
  frequency_penalty:
    label: "Frequency Penalty"
    slider:
      min_value: 0.0
      max_value: 2.0
      value: 0.0
      step: 0.1
      help: "Penalize the model for repeating the same words or phrases."
  presence_penalty:
    label: "Presence Penalty"
    slider:
      min_value: 0.0
      max_value: 2.0
      value: 0.0
      step: 0.1
      help: "Penalize the model for using words or phrases already used in the conversation."
  stop:
    label: "Stop Sequences"
    input:
      value: ""
      help: "Specify sequences that the model should stop generating a response when encountered."
